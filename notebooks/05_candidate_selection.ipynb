{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139ee5bc",
   "metadata": {},
   "source": [
    "# Corpus Characterisation & Candidate Selection\n",
    "\n",
    "This notebook implements the first phase of the analytical framework: Corpus Characterization and Candidate Selection. The objective is to move from the full corpus of papers to a defensible, balanced subset of approximately 50-75 key papers for in-depth qualitative analysis. This is achieved using a \"Two-Bucket\" strategy to identify both \"Foundational Pillars\" and \"Rising Stars\" in the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f233733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stahlma/.pyenv/versions/causal-rl-ev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Connected to Neo4j.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# --- Connect to Neo4j ---\n",
    "load_dotenv()\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "AUTH = (os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "\n",
    "# --- Helper Function to run queries and return a DataFrame ---\n",
    "def query_to_dataframe(driver, query, **params):\n",
    "    \"\"\"\n",
    "    This function executes a Cypher query against the database\n",
    "    and returns the results as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, **params)\n",
    "        return pd.DataFrame([r.data() for r in result])\n",
    "\n",
    "print(\"Setup complete. Connected to Neo4j.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3c350",
   "metadata": {},
   "source": [
    "## 1. Fetching and Preparing the Corpus Data\n",
    "The process begins by fetching all papers from the graph, along with their associated in-corpus citation counts. To measure network influence, the PageRank algorithm is then run on the full citation graph. The resulting scores are merged to create a master DataFrame, which forms the base dataset upon which all subsequent scoring will be performed.\n",
    "\n",
    "Page Rank: Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). The PageRank citation ranking: Bringing order to the web. Stanford InfoLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "261cfd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching full corpus data from Neo4j...\n",
      "Fetching citation network for PageRank calculation...\n",
      "Corpus prepared with 2055 papers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "overall_citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_corpus_citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pagerank",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "39eb103e-2da7-4eb5-9f2d-0dce1d65cadd",
       "rows": [
        [
         "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8",
         "Demand response of a heterogeneous cluster of electric water heaters using batch reinforcement learning",
         "2014",
         "74",
         "7",
         "Power Systems Computation Conference",
         "0.019175755051171948"
        ],
        [
         "745a134eca192982e8e0c16d6f36cfe24f9bdd08",
         "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search",
         "2018",
         "143",
         "11",
         "International Conference on Learning Representations",
         "0.01827489864983827"
        ],
        [
         "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4",
         "Reinforcement learning for demand response: A review of algorithms and modeling techniques",
         "2019",
         "604",
         "31",
         "Applied Energy",
         "0.01678068244207389"
        ],
        [
         "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5",
         "Model-Free Real-Time EV Charging Scheduling Based on Deep Reinforcement Learning",
         "2019",
         "393",
         "39",
         "IEEE Transactions on Smart Grid",
         "0.01597513182993388"
        ],
        [
         "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0",
         "Optimal Demand Response Using Device-Based Reinforcement Learning",
         "2014",
         "236",
         "18",
         "IEEE Transactions on Smart Grid",
         "0.013681786824852524"
        ],
        [
         "171d3d9f6828ad880d7d95217f44db4fb0266a1c",
         "Exploring deterministic frequency deviations with explainable AI",
         "2021",
         "15",
         "2",
         "IEEE International Conference on Smart Grid Communications",
         "0.013559387937133505"
        ],
        [
         "db8cdc3f4a8eb4fd9051063c43b6f4e62bec3c7c",
         "Revealing drivers and risks for power grid frequency stability with explainable AI",
         "2021",
         "58",
         "2",
         "Patterns",
         "0.013559387937133505"
        ],
        [
         "bd7638ddbbe249c3e6070f951b39f961b5e61cb5",
         "Incentive-based demand response for smart grid with reinforcement learning and deep neural network",
         "2019",
         "320",
         "20",
         "Applied Energy",
         "0.013148710592523614"
        ],
        [
         "a615c02ed0ca97489cb5b61309154050ae34da37",
         "Reinforcement Learning of Heuristic EV Fleet Charging in a Day-Ahead Electricity Market",
         "2015",
         "178",
         "14",
         "IEEE Transactions on Smart Grid",
         "0.0102044053487635"
        ],
        [
         "cd3c9cba90f778ada660a462d58573756c60fb27",
         "Reinforcement Learning-Based Plug-in Electric Vehicle Charging With Forecasted Price",
         "2017",
         "157",
         "24",
         "IEEE Transactions on Vehicular Technology",
         "0.009878363574428293"
        ],
        [
         "4ebbd178639ed31e6ca1eac7ff0fe17bcb1d1090",
         "Demand Response for Home Energy Management Using Reinforcement Learning and Artificial Neural Network",
         "2019",
         "286",
         "16",
         "IEEE Transactions on Smart Grid",
         "0.00975219637979783"
        ],
        [
         "7cd12c64940d2ee4bd5fce4b959e49bbe9a92c39",
         "Counterfactual Off-Policy Evaluation with Gumbel-Max Structural Causal Models",
         "2019",
         "177",
         "9",
         "International Conference on Machine Learning",
         "0.009274751982376504"
        ],
        [
         "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500",
         "Decision Transformer: Reinforcement Learning via Sequence Modeling",
         "2021",
         "1747",
         "7",
         "Neural Information Processing Systems",
         "0.009017091347846728"
        ],
        [
         "996e12d3bb53ba54be815475e15c32a5d2a12428",
         "A Dynamic pricing demand response algorithm for smart grid: Reinforcement learning approach",
         "2018",
         "360",
         "18",
         "Applied Energy",
         "0.00867174974522749"
        ],
        [
         "037b2b6ad206ba2ff657dc8dd31f2942c03d5466",
         "Definition and Evaluation of Model-Free Coordination of Electrical Vehicle Charging With Reinforcement Learning",
         "2018",
         "109",
         "16",
         "IEEE Transactions on Smart Grid",
         "0.0075287293066312565"
        ],
        [
         "86257a79958f2bb351970272b1a1673c55227ed6",
         "Deep Reinforcement Learning for Power System Applications: An Overview",
         "2020",
         "348",
         "8",
         "Information Fusion",
         "0.007348885037264009"
        ],
        [
         "249cb49a54642a2d6cfdad2b791ba87b6e737d37",
         "Reinforcement Learning for Real-Time Pricing and Scheduling Control in EV Charging Stations",
         "2021",
         "167",
         "17",
         "IEEE Transactions on Industrial Informatics",
         "0.007318958313932952"
        ],
        [
         "c5d078db82739b5c3f01df0e662274d2a5fd1d37",
         "Coordination of Electric Vehicle Charging Through Multiagent Reinforcement Learning",
         "2020",
         "95",
         "9",
         "IEEE Transactions on Smart Grid",
         "0.006989037106585395"
        ],
        [
         "165e53d49dcab412e69a0ae3a2f0291510568855",
         "Reinforcement Learning Based EV Charging Management Systemsâ€“A Review",
         "2021",
         "126",
         "14",
         "IEEE Access",
         "0.0065624510701028085"
        ],
        [
         "2342b32e245989103dbc56d6f07f1400f4fd2e06",
         "CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning",
         "2020",
         "124",
         "7",
         "International Conference on Learning Representations",
         "0.006528054517028083"
        ],
        [
         "50fa839e504ba79d075526d7d560ac3da69c3187",
         "Reinforcement Learning Applied to an Electric Water Heater: From Theory to Practice",
         "2015",
         "141",
         "12",
         "IEEE Transactions on Smart Grid",
         "0.006366218676717834"
        ],
        [
         "b4d08620b6cd42d60795fc3104fcd9a3f060bbe4",
         "CDDPG: A Deep-Reinforcement-Learning-Based Approach for Electric Vehicle Charging Control",
         "2021",
         "122",
         "17",
         "IEEE Internet of Things Journal",
         "0.006064518967668727"
        ],
        [
         "f844925066c3de9cd9ad662059e25a9d47a59843",
         "Causal Discovery with Reinforcement Learning",
         "2019",
         "248",
         "5",
         "International Conference on Learning Representations",
         "0.005853380214692007"
        ],
        [
         "5bab61de56dacadbc72908e955971c22ef894861",
         "Transfer Learning in Multi-Armed Bandits: A Causal Approach",
         "2017",
         "81",
         "5",
         "International Joint Conference on Artificial Intelligence",
         "0.005712748236607743"
        ],
        [
         "67a65737d17713ae8bee1b69b853ee658bc6626f",
         "Generalized Hidden Parameter MDPs Transferable Model-based RL in a Handful of Trials",
         "2020",
         "37",
         "3",
         "AAAI Conference on Artificial Intelligence",
         "0.0056372345171384714"
        ],
        [
         "4196d095cc2eb9c94484a3fe203bc8b25d4c8f34",
         "Multi-agent deep reinforcement learning approach for EV charging scheduling in a smart grid",
         "2022",
         "100",
         "5",
         "Applied Energy",
         "0.005593380733694594"
        ],
        [
         "2bb5873a1a96205fb86cee12bf137f48ef13f675",
         "Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning",
         "2020",
         "66",
         "8",
         "International Conference on Machine Learning",
         "0.005547793780977595"
        ],
        [
         "36c1bdcb8a6b9fd410e5ed069d12fa0975b52b6c",
         "Smart Charging of Electric Vehicles using Reinforcement Learning",
         "2013",
         "17",
         "4",
         "Trading Agent Design and Analysis",
         "0.005430522801913177"
        ],
        [
         "287cd1b982d8090f2b112a9c22da87df6a6598d7",
         "Residential Demand Response Applications Using Batch Reinforcement Learning",
         "2015",
         "14",
         "2",
         "arXiv.org",
         "0.0054096306577763"
        ],
        [
         "ba8e1b2f1a0d1864c033ef99f89d91bb94c87785",
         "Multi-agent deep reinforcement learning based demand response for discrete manufacturing systems energy management",
         "2020",
         "125",
         "7",
         "Applied Energy",
         "0.0052666485395662975"
        ],
        [
         "7b3c36c30bc27813e7cc5a9d4bd0570e7169e467",
         "Deep Reinforcement Learning for Charging Scheduling of Electric Vehicles Considering Distribution Network Voltage Stability",
         "2023",
         "36",
         "6",
         "Italian National Conference on Sensors",
         "0.0050385473489653835"
        ],
        [
         "871e71d2fd85e9c37596832e78be6488f10f0cf0",
         "Peak shaving of a heterogeneous cluster of residential flexibility carriers using reinforcement learning",
         "2013",
         "30",
         "6",
         "IEEE PES ISGT Europe 2013",
         "0.004992184020376157"
        ],
        [
         "05391e6663cddf7ba7708aac5d6fe0ef9f7c73d0",
         "Intelligent Electric Vehicle Charging Recommendation Based on Multi-Agent Reinforcement Learning",
         "2021",
         "86",
         "5",
         "The Web Conference",
         "0.00498265453007965"
        ],
        [
         "aa475afc251c6048818790d0368ca10222888920",
         "Smart Online Charging Algorithm for Electric Vehicles via Customized Actorâ€“Critic Learning",
         "2021",
         "67",
         "10",
         "IEEE Internet of Things Journal",
         "0.004933049498722563"
        ],
        [
         "6817a19c35cbb32854a9f4754c09f81048cf2853",
         "Deep Reinforcement Learning Method for Demand Response Management of Interruptible Load",
         "2020",
         "143",
         "11",
         "IEEE Transactions on Smart Grid",
         "0.0048629694027698366"
        ],
        [
         "ce08c2e299ecf576788026babb177c8764a6862c",
         "Development and Evaluation of a Smart Charging Strategy for an Electric Vehicle Fleet Based on Reinforcement Learning",
         "2021",
         "125",
         "9",
         "Applied Energy",
         "0.004831680809754968"
        ],
        [
         "35ae797eb7921a0c1ad2cf7dbe783da7817547f2",
         "Optimal Scheduling of Isolated Microgrids Using Automated Reinforcement Learning-Based Multi-Period Forecasting",
         "2021",
         "186",
         "4",
         "IEEE Transactions on Sustainable Energy",
         "0.004783338817804605"
        ],
        [
         "ef18f8f8ef2cbe5686dbf4c0ccdb6b9d434537a4",
         "Reinforcement Learning-Based Energy Management of Smart Home with Rooftop Solar Photovoltaic System, Energy Storage System, and Home Appliances",
         "2019",
         "102",
         "8",
         "Italian National Conference on Sensors",
         "0.004728745997028355"
        ],
        [
         "da19a6bdf9d81177d6b60f89716f5126b19acfd7",
         "An Edge-Cloud Integrated Solution for Buildings Demand Response Using Reinforcement Learning",
         "2021",
         "63",
         "5",
         "IEEE Transactions on Smart Grid",
         "0.004727623852922339"
        ],
        [
         "4c2798b8618db6af5fc9f85c1097c575ec77c4a0",
         "OCTOPUS: Deep Reinforcement Learning for Holistic Smart Building Control",
         "2019",
         "131",
         "4",
         "International Conference on Systems for Energy-Efficient Built Environments",
         "0.004583620646312088"
        ],
        [
         "e0f06526e9ff8bb82055052e67f6d9908817ddd8",
         "Electric Vehicle Charging and Discharging Algorithm Based on Reinforcement Learning with Data-Driven Approach in Dynamic Pricing Scheme",
         "2020",
         "46",
         "7",
         "Energies",
         "0.0045493788530944854"
        ],
        [
         "8d06a30a270ff6dc763458dcedeea500fbf249e0",
         "A Multi-Agent Reinforcement Learning-Based Data-Driven Method for Home Energy Management",
         "2020",
         "286",
         "12",
         "IEEE Transactions on Smart Grid",
         "0.004429528309463967"
        ],
        [
         "6069e7b1f734eea4a3b64466a81b6c8fe1c4ed37",
         "Deep Reinforcement Learning Microgrid Optimization Strategy Considering Priority Flexible Demand Side",
         "2022",
         "26",
         "3",
         "Italian National Conference on Sensors",
         "0.0044141659403361426"
        ],
        [
         "674191d5a65cbfd110a3d1fc3a845e973fca10a6",
         "Optimal Policy Characterization Enhanced Actor-Critic Approach for Electric Vehicle Charging Scheduling in a Power Distribution Network",
         "2021",
         "75",
         "11",
         "IEEE Transactions on Smart Grid",
         "0.0041335894201695615"
        ],
        [
         "d405c12c54f506d4aa0cc1df1e5893cd61452790",
         "Effective Charging Planning Based on Deep Reinforcement Learning for Electric Vehicles",
         "2021",
         "102",
         "6",
         "IEEE transactions on intelligent transportation systems (Print)",
         "0.0041020346084361696"
        ],
        [
         "ba54f632c4edf6aaa44bbdfc31d1942a379352c3",
         "Asynchronous Deep Reinforcement Learning for Collaborative Task Computing and On-Demand Resource Allocation in Vehicular Edge Computing",
         "2023",
         "109",
         "2",
         "IEEE transactions on intelligent transportation systems (Print)",
         "0.0039949203550607324"
        ],
        [
         "765d8b5ab2c8f36f070b13dad5f71455468b11b0",
         "Deep Reinforcement Learning for Continuous Electric Vehicles Charging Control With Dynamic User Behaviors",
         "2021",
         "120",
         "9",
         "IEEE Transactions on Smart Grid",
         "0.0038567337291011998"
        ],
        [
         "13c1b08f6a9862b3e32548e612830cb3e41f1a32",
         "Intelligent Residential Energy Management System Using Deep Reinforcement Learning",
         "2020",
         "42",
         "7",
         "IEEE Systems Journal",
         "0.0037892990946309987"
        ],
        [
         "ca6e5783a856230f41a7f7b303a62c5f59dc9649",
         "CityLearn v1.0: An OpenAI Gym Environment for Demand Response with Deep Reinforcement Learning",
         "2019",
         "132",
         "4",
         "International Conference on Systems for Energy-Efficient Built Environments",
         "0.0037842728894638914"
        ],
        [
         "cc9fb0399836d4e589b874da2085674eeb105587",
         "Reinforcement Learning Based Algorithm for the Maximization of EV Charging Station Revenue",
         "2014",
         "25",
         "5",
         "International Conference on Mathematics and Computers in Sciences and in Industry",
         "0.0037763844194142514"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>overall_citations</th>\n",
       "      <th>in_corpus_citations</th>\n",
       "      <th>venue</th>\n",
       "      <th>pagerank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8db33a0a1c3ab2b45f9229896e9e2a02e309bab8</th>\n",
       "      <td>Demand response of a heterogeneous cluster of ...</td>\n",
       "      <td>2014</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>Power Systems Computation Conference</td>\n",
       "      <td>0.019176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745a134eca192982e8e0c16d6f36cfe24f9bdd08</th>\n",
       "      <td>Woulda, Coulda, Shoulda: Counterfactually-Guid...</td>\n",
       "      <td>2018</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>0.018275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648ea87fe7f99ca8ea5090cb1ba40242299ef4c4</th>\n",
       "      <td>Reinforcement learning for demand response: A ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>604</td>\n",
       "      <td>31</td>\n",
       "      <td>Applied Energy</td>\n",
       "      <td>0.016781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59021ecd3fd15c59b8b774c87ae974c9fffe9fa5</th>\n",
       "      <td>Model-Free Real-Time EV Charging Scheduling Ba...</td>\n",
       "      <td>2019</td>\n",
       "      <td>393</td>\n",
       "      <td>39</td>\n",
       "      <td>IEEE Transactions on Smart Grid</td>\n",
       "      <td>0.015975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0</th>\n",
       "      <td>Optimal Demand Response Using Device-Based Rei...</td>\n",
       "      <td>2014</td>\n",
       "      <td>236</td>\n",
       "      <td>18</td>\n",
       "      <td>IEEE Transactions on Smart Grid</td>\n",
       "      <td>0.013682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3afbead850747d4a98c24cca0af1f5e78a128396</th>\n",
       "      <td>An effective energy management Layout-Based re...</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Solar Energy</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8addbf4b72e2e7c8ee85f8b1d03b3a2298b741a6</th>\n",
       "      <td>Power Flow Management in Electric Vehicles Cha...</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>IEEE Congress on Evolutionary Computation</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267ada92e896d061d401665ab1443b570132ad49</th>\n",
       "      <td>A Multi-Level Reinforcement-Learning Model of ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019 Conference on Cognitive Computational Neu...</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387a17823d7c47c0bd3390a124708933032989e0</th>\n",
       "      <td>Generalized Decision Transformer for Offline H...</td>\n",
       "      <td>2021</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350347808e5011999b6f90deb996465a2e7674e7</th>\n",
       "      <td>Human-Level Reinforcement Learning through The...</td>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "paperId                                                                                       \n",
       "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8  Demand response of a heterogeneous cluster of ...   \n",
       "745a134eca192982e8e0c16d6f36cfe24f9bdd08  Woulda, Coulda, Shoulda: Counterfactually-Guid...   \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4  Reinforcement learning for demand response: A ...   \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5  Model-Free Real-Time EV Charging Scheduling Ba...   \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0  Optimal Demand Response Using Device-Based Rei...   \n",
       "...                                                                                     ...   \n",
       "3afbead850747d4a98c24cca0af1f5e78a128396  An effective energy management Layout-Based re...   \n",
       "8addbf4b72e2e7c8ee85f8b1d03b3a2298b741a6  Power Flow Management in Electric Vehicles Cha...   \n",
       "267ada92e896d061d401665ab1443b570132ad49  A Multi-Level Reinforcement-Learning Model of ...   \n",
       "387a17823d7c47c0bd3390a124708933032989e0  Generalized Decision Transformer for Offline H...   \n",
       "350347808e5011999b6f90deb996465a2e7674e7  Human-Level Reinforcement Learning through The...   \n",
       "\n",
       "                                          year  overall_citations  \\\n",
       "paperId                                                             \n",
       "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8  2014                 74   \n",
       "745a134eca192982e8e0c16d6f36cfe24f9bdd08  2018                143   \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4  2019                604   \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5  2019                393   \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0  2014                236   \n",
       "...                                        ...                ...   \n",
       "3afbead850747d4a98c24cca0af1f5e78a128396  2023                 39   \n",
       "8addbf4b72e2e7c8ee85f8b1d03b3a2298b741a6  2020                 16   \n",
       "267ada92e896d061d401665ab1443b570132ad49  2019                  3   \n",
       "387a17823d7c47c0bd3390a124708933032989e0  2021                107   \n",
       "350347808e5011999b6f90deb996465a2e7674e7  2021                 52   \n",
       "\n",
       "                                          in_corpus_citations  \\\n",
       "paperId                                                         \n",
       "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8                    7   \n",
       "745a134eca192982e8e0c16d6f36cfe24f9bdd08                   11   \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4                   31   \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5                   39   \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0                   18   \n",
       "...                                                       ...   \n",
       "3afbead850747d4a98c24cca0af1f5e78a128396                    1   \n",
       "8addbf4b72e2e7c8ee85f8b1d03b3a2298b741a6                    1   \n",
       "267ada92e896d061d401665ab1443b570132ad49                    1   \n",
       "387a17823d7c47c0bd3390a124708933032989e0                    2   \n",
       "350347808e5011999b6f90deb996465a2e7674e7                    1   \n",
       "\n",
       "                                                                                      venue  \\\n",
       "paperId                                                                                       \n",
       "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8               Power Systems Computation Conference   \n",
       "745a134eca192982e8e0c16d6f36cfe24f9bdd08  International Conference on Learning Represent...   \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4                                     Applied Energy   \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5                    IEEE Transactions on Smart Grid   \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0                    IEEE Transactions on Smart Grid   \n",
       "...                                                                                     ...   \n",
       "3afbead850747d4a98c24cca0af1f5e78a128396                                       Solar Energy   \n",
       "8addbf4b72e2e7c8ee85f8b1d03b3a2298b741a6          IEEE Congress on Evolutionary Computation   \n",
       "267ada92e896d061d401665ab1443b570132ad49  2019 Conference on Cognitive Computational Neu...   \n",
       "387a17823d7c47c0bd3390a124708933032989e0  International Conference on Learning Represent...   \n",
       "350347808e5011999b6f90deb996465a2e7674e7                                          arXiv.org   \n",
       "\n",
       "                                          pagerank  \n",
       "paperId                                             \n",
       "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8  0.019176  \n",
       "745a134eca192982e8e0c16d6f36cfe24f9bdd08  0.018275  \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4  0.016781  \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5  0.015975  \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0  0.013682  \n",
       "...                                            ...  \n",
       "3afbead850747d4a98c24cca0af1f5e78a128396  0.002737  \n",
       "8addbf4b72e2e7c8ee85f8b1d03b3a2298b741a6  0.002737  \n",
       "267ada92e896d061d401665ab1443b570132ad49  0.002737  \n",
       "387a17823d7c47c0bd3390a124708933032989e0  0.002737  \n",
       "350347808e5011999b6f90deb996465a2e7674e7  0.002737  \n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This query fetches all papers and their in-corpus citation counts.\n",
    "corpus_query = \"\"\"\n",
    "MATCH (p:Paper)\n",
    "OPTIONAL MATCH (p)-[:PUBLISHED_IN]->(v:Venue)\n",
    "OPTIONAL MATCH (p)<-[:CITES]-(citer)\n",
    "WITH p, v, count(citer) as in_corpus_citations\n",
    "RETURN\n",
    "    p.paperId AS paperId,\n",
    "    p.title AS title,\n",
    "    p.year AS year,\n",
    "    p.citation_count AS overall_citations,\n",
    "    in_corpus_citations,\n",
    "    v.name AS venue\n",
    "\"\"\"\n",
    "print(\"Fetching full corpus data from Neo4j...\")\n",
    "corpus_df = query_to_dataframe(driver, corpus_query)\n",
    "corpus_df.set_index('paperId', inplace=True)\n",
    "\n",
    "\n",
    "# This query fetches the citation network to calculate PageRank.\n",
    "citation_network_query = \"\"\"\n",
    "MATCH (p1:Paper)-[:CITES]->(p2:Paper)\n",
    "RETURN p1.paperId AS source, p2.paperId AS target\n",
    "\"\"\"\n",
    "print(\"Fetching citation network for PageRank calculation...\")\n",
    "citation_df = query_to_dataframe(driver, citation_network_query)\n",
    "\n",
    "# It creates a NetworkX graph and calculates PageRank.\n",
    "G = nx.from_pandas_edgelist(citation_df, 'source', 'target', create_using=nx.DiGraph())\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# The PageRank scores are added to the main DataFrame.\n",
    "corpus_df['pagerank'] = corpus_df.index.map(pagerank)\n",
    "corpus_df['pagerank'] = corpus_df['pagerank'].fillna(0)\n",
    "\n",
    "print(f\"Corpus prepared with {len(corpus_df)} papers.\")\n",
    "display(corpus_df.sort_values(by='pagerank', ascending=False).head(75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bda78",
   "metadata": {},
   "source": [
    "## 2. Bucket A: Identifying Foundational Pillars\n",
    "The \"Foundational Pillars\" are identified using a composite \"Foundational Score.\" This score is a weighted average of three normalized metrics: overall citations (external influence), in-corpus citations (domain centrality), and PageRank (network influence). This multi-faceted approach provides a robust measure of a paper's established importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 100 foundational papers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "foundational_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d2255249-3772-4b33-9293-741b57fe2f98",
       "rows": [
        [
         "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5",
         "Model-Free Real-Time EV Charging Scheduling Based on Deep Reinforcement Learning",
         "2019",
         "0.7949184459921694"
        ],
        [
         "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4",
         "Reinforcement learning for demand response: A review of algorithms and modeling techniques",
         "2019",
         "0.729112681305095"
        ],
        [
         "bd7638ddbbe249c3e6070f951b39f961b5e61cb5",
         "Incentive-based demand response for smart grid with reinforcement learning and deep neural network",
         "2019",
         "0.49875284935690967"
        ],
        [
         "cd3c9cba90f778ada660a462d58573756c60fb27",
         "Reinforcement Learning-Based Plug-in Electric Vehicle Charging With Forecasted Price",
         "2017",
         "0.4802105600602676"
        ],
        [
         "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0",
         "Optimal Demand Response Using Device-Based Reinforcement Learning",
         "2014",
         "0.4718351856493451"
        ],
        [
         "745a134eca192982e8e0c16d6f36cfe24f9bdd08",
         "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search",
         "2018",
         "0.4433028844332949"
        ],
        [
         "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500",
         "Decision Transformer: Reinforcement Learning via Sequence Modeling",
         "2021",
         "0.4308137795293469"
        ],
        [
         "996e12d3bb53ba54be815475e15c32a5d2a12428",
         "A Dynamic pricing demand response algorithm for smart grid: Reinforcement learning approach",
         "2018",
         "0.4076501444778405"
        ],
        [
         "8db33a0a1c3ab2b45f9229896e9e2a02e309bab8",
         "Demand response of a heterogeneous cluster of electric water heaters using batch reinforcement learning",
         "2014",
         "0.39821525545624"
        ],
        [
         "4ebbd178639ed31e6ca1eac7ff0fe17bcb1d1090",
         "Demand Response for Home Energy Management Using Reinforcement Learning and Artificial Neural Network",
         "2019",
         "0.39044077659206067"
        ],
        [
         "a615c02ed0ca97489cb5b61309154050ae34da37",
         "Reinforcement Learning of Heuristic EV Fleet Charging in a Day-Ahead Electricity Market",
         "2015",
         "0.35951039706013"
        ],
        [
         "249cb49a54642a2d6cfdad2b791ba87b6e737d37",
         "Reinforcement Learning for Real-Time Pricing and Scheduling Control in EV Charging Stations",
         "2021",
         "0.35157052038874725"
        ],
        [
         "037b2b6ad206ba2ff657dc8dd31f2942c03d5466",
         "Definition and Evaluation of Model-Free Coordination of Electrical Vehicle Charging With Reinforcement Learning",
         "2018",
         "0.3353918692603989"
        ],
        [
         "b4d08620b6cd42d60795fc3104fcd9a3f060bbe4",
         "CDDPG: A Deep-Reinforcement-Learning-Based Approach for Electric Vehicle Charging Control",
         "2021",
         "0.3267934348722543"
        ],
        [
         "165e53d49dcab412e69a0ae3a2f0291510568855",
         "Reinforcement Learning Based EV Charging Management Systemsâ€“A Review",
         "2021",
         "0.29657985030334394"
        ],
        [
         "7cd12c64940d2ee4bd5fce4b959e49bbe9a92c39",
         "Counterfactual Off-Policy Evaluation with Gumbel-Max Structural Causal Models",
         "2019",
         "0.2807491513378315"
        ],
        [
         "50fa839e504ba79d075526d7d560ac3da69c3187",
         "Reinforcement Learning Applied to an Electric Water Heater: From Theory to Practice",
         "2015",
         "0.2695860463758508"
        ],
        [
         "86257a79958f2bb351970272b1a1673c55227ed6",
         "Deep Reinforcement Learning for Power System Applications: An Overview",
         "2020",
         "0.2573753376799156"
        ],
        [
         "8d06a30a270ff6dc763458dcedeea500fbf249e0",
         "A Multi-Agent Reinforcement Learning-Based Data-Driven Method for Home Energy Management",
         "2020",
         "0.25588688454864295"
        ],
        [
         "db8cdc3f4a8eb4fd9051063c43b6f4e62bec3c7c",
         "Revealing drivers and risks for power grid frequency stability with explainable AI",
         "2021",
         "0.2444142893468615"
        ],
        [
         "171d3d9f6828ad880d7d95217f44db4fb0266a1c",
         "Exploring deterministic frequency deviations with explainable AI",
         "2021",
         "0.23949156467599717"
        ],
        [
         "c5d078db82739b5c3f01df0e662274d2a5fd1d37",
         "Coordination of Electric Vehicle Charging Through Multiagent Reinforcement Learning",
         "2020",
         "0.23560217941497302"
        ],
        [
         "6817a19c35cbb32854a9f4754c09f81048cf2853",
         "Deep Reinforcement Learning Method for Demand Response Management of Interruptible Load",
         "2020",
         "0.23347653009244596"
        ],
        [
         "674191d5a65cbfd110a3d1fc3a845e973fca10a6",
         "Optimal Policy Characterization Enhanced Actor-Critic Approach for Electric Vehicle Charging Scheduling in a Power Distribution Network",
         "2021",
         "0.21428078467346592"
        ],
        [
         "aa475afc251c6048818790d0368ca10222888920",
         "Smart Online Charging Algorithm for Electric Vehicles via Customized Actorâ€“Critic Learning",
         "2021",
         "0.21305177359024563"
        ],
        [
         "2342b32e245989103dbc56d6f07f1400f4fd2e06",
         "CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning",
         "2020",
         "0.20606917095742822"
        ],
        [
         "ce08c2e299ecf576788026babb177c8764a6862c",
         "Development and Evaluation of a Smart Charging Strategy for an Electric Vehicle Fleet Based on Reinforcement Learning",
         "2021",
         "0.20528532661900956"
        ],
        [
         "2bb5873a1a96205fb86cee12bf137f48ef13f675",
         "Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning",
         "2020",
         "0.19691378999336254"
        ],
        [
         "765d8b5ab2c8f36f070b13dad5f71455468b11b0",
         "Deep Reinforcement Learning for Continuous Electric Vehicles Charging Control With Dynamic User Behaviors",
         "2021",
         "0.18946010803588004"
        ],
        [
         "ef18f8f8ef2cbe5686dbf4c0ccdb6b9d434537a4",
         "Reinforcement Learning-Based Energy Management of Smart Home with Rooftop Solar Photovoltaic System, Energy Storage System, and Home Appliances",
         "2019",
         "0.1882213385281447"
        ],
        [
         "ba8e1b2f1a0d1864c033ef99f89d91bb94c87785",
         "Multi-agent deep reinforcement learning based demand response for discrete manufacturing systems energy management",
         "2020",
         "0.18644926477707163"
        ],
        [
         "f844925066c3de9cd9ad662059e25a9d47a59843",
         "Causal Discovery with Reinforcement Learning",
         "2019",
         "0.18406879495685893"
        ],
        [
         "2c00c0edbc29712065beabaed5e3ce425b9232dc",
         "Reinforcement learning for whole-building HVAC control and demand response",
         "2020",
         "0.17243657243363392"
        ],
        [
         "e0f06526e9ff8bb82055052e67f6d9908817ddd8",
         "Electric Vehicle Charging and Discharging Algorithm Based on Reinforcement Learning with Data-Driven Approach in Dynamic Pricing Scheme",
         "2020",
         "0.16618368032050534"
        ],
        [
         "067cc6bc8d666158a7fa23ba324e9a4763bf4fa6",
         "Intelligent Multi-Microgrid Energy Management Based on Deep Neural Network and Model-Free Reinforcement Learning",
         "2020",
         "0.1637057129518611"
        ],
        [
         "4196d095cc2eb9c94484a3fe203bc8b25d4c8f34",
         "Multi-agent deep reinforcement learning approach for EV charging scheduling in a smart grid",
         "2022",
         "0.163057835211783"
        ],
        [
         "5bab61de56dacadbc72908e955971c22ef894861",
         "Transfer Learning in Multi-Armed Bandits: A Causal Approach",
         "2017",
         "0.16275015320113306"
        ],
        [
         "7b3c36c30bc27813e7cc5a9d4bd0570e7169e467",
         "Deep Reinforcement Learning for Charging Scheduling of Electric Vehicles Considering Distribution Network Voltage Stability",
         "2023",
         "0.15987126934306498"
        ],
        [
         "871e71d2fd85e9c37596832e78be6488f10f0cf0",
         "Peak shaving of a heterogeneous cluster of residential flexibility carriers using reinforcement learning",
         "2013",
         "0.15845903458689709"
        ],
        [
         "13c1b08f6a9862b3e32548e612830cb3e41f1a32",
         "Intelligent Residential Energy Management System Using Deep Reinforcement Learning",
         "2020",
         "0.15383449043487704"
        ],
        [
         "d405c12c54f506d4aa0cc1df1e5893cd61452790",
         "Effective Charging Planning Based on Deep Reinforcement Learning for Electric Vehicles",
         "2021",
         "0.15277556642076467"
        ],
        [
         "05391e6663cddf7ba7708aac5d6fe0ef9f7c73d0",
         "Intelligent Electric Vehicle Charging Recommendation Based on Multi-Agent Reinforcement Learning",
         "2021",
         "0.15190042548934227"
        ],
        [
         "35ae797eb7921a0c1ad2cf7dbe783da7817547f2",
         "Optimal Scheduling of Isolated Microgrids Using Automated Reinforcement Learning-Based Multi-Period Forecasting",
         "2021",
         "0.14740986398472508"
        ],
        [
         "da19a6bdf9d81177d6b60f89716f5126b19acfd7",
         "An Edge-Cloud Integrated Solution for Buildings Demand Response Using Reinforcement Learning",
         "2021",
         "0.1452774476018862"
        ],
        [
         "36c1bdcb8a6b9fd410e5ed069d12fa0975b52b6c",
         "Smart Charging of Electric Vehicles using Reinforcement Learning",
         "2013",
         "0.13818744642693961"
        ],
        [
         "4c2798b8618db6af5fc9f85c1097c575ec77c4a0",
         "OCTOPUS: Deep Reinforcement Learning for Holistic Smart Building Control",
         "2019",
         "0.1379888137156204"
        ],
        [
         "119ad6b55970b90696c620b7b3985b86845cb533",
         "Counterfactual Data Augmentation using Locally Factored Dynamics",
         "2020",
         "0.13133557955542802"
        ],
        [
         "67a65737d17713ae8bee1b69b853ee658bc6626f",
         "Generalized Hidden Parameter MDPs Transferable Model-based RL in a Handful of Trials",
         "2020",
         "0.13089052723941796"
        ],
        [
         "d7979b0381077400a81ae98004373b1fae7b80ef",
         "Multiagent Reinforcement Learning for Community Energy Management to Mitigate Peak Rebounds Under Renewable Energy Uncertainty",
         "2022",
         "0.1290383264460138"
        ],
        [
         "cc9fb0399836d4e589b874da2085674eeb105587",
         "Reinforcement Learning Based Algorithm for the Maximization of EV Charging Station Revenue",
         "2014",
         "0.1260452243827266"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>foundational_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59021ecd3fd15c59b8b774c87ae974c9fffe9fa5</th>\n",
       "      <td>Model-Free Real-Time EV Charging Scheduling Ba...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.794918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648ea87fe7f99ca8ea5090cb1ba40242299ef4c4</th>\n",
       "      <td>Reinforcement learning for demand response: A ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.729113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bd7638ddbbe249c3e6070f951b39f961b5e61cb5</th>\n",
       "      <td>Incentive-based demand response for smart grid...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.498753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd3c9cba90f778ada660a462d58573756c60fb27</th>\n",
       "      <td>Reinforcement Learning-Based Plug-in Electric ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.480211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0</th>\n",
       "      <td>Optimal Demand Response Using Device-Based Rei...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.471835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816ea64552b56ca901939e8506ff7802251dd783</th>\n",
       "      <td>Dynamic Pricing Strategy of Electric Vehicle A...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.087352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8605228dc596ca1701a3e19d6eff49225e399b05</th>\n",
       "      <td>Dynamic pricing and energy management for prof...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.087345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95900962a264ce89610877a323334c441c93c3b2</th>\n",
       "      <td>Demand Response Management for Industrial Faci...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.087227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2c70c4d23c98dd4e77234fe0720595d3d565a12</th>\n",
       "      <td>Systematic Evaluation of Causal Discovery in V...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.086073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd6dc29630b4f8e9c88f3da070be23f6ce0e28d9</th>\n",
       "      <td>An Intelligent Recommendation for Intelligentl...</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.085388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "paperId                                                                                       \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5  Model-Free Real-Time EV Charging Scheduling Ba...   \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4  Reinforcement learning for demand response: A ...   \n",
       "bd7638ddbbe249c3e6070f951b39f961b5e61cb5  Incentive-based demand response for smart grid...   \n",
       "cd3c9cba90f778ada660a462d58573756c60fb27  Reinforcement Learning-Based Plug-in Electric ...   \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0  Optimal Demand Response Using Device-Based Rei...   \n",
       "...                                                                                     ...   \n",
       "816ea64552b56ca901939e8506ff7802251dd783  Dynamic Pricing Strategy of Electric Vehicle A...   \n",
       "8605228dc596ca1701a3e19d6eff49225e399b05  Dynamic pricing and energy management for prof...   \n",
       "95900962a264ce89610877a323334c441c93c3b2  Demand Response Management for Industrial Faci...   \n",
       "b2c70c4d23c98dd4e77234fe0720595d3d565a12  Systematic Evaluation of Causal Discovery in V...   \n",
       "fd6dc29630b4f8e9c88f3da070be23f6ce0e28d9  An Intelligent Recommendation for Intelligentl...   \n",
       "\n",
       "                                          year  foundational_score  \n",
       "paperId                                                             \n",
       "59021ecd3fd15c59b8b774c87ae974c9fffe9fa5  2019            0.794918  \n",
       "648ea87fe7f99ca8ea5090cb1ba40242299ef4c4  2019            0.729113  \n",
       "bd7638ddbbe249c3e6070f951b39f961b5e61cb5  2019            0.498753  \n",
       "cd3c9cba90f778ada660a462d58573756c60fb27  2017            0.480211  \n",
       "0aa23eca1bf2302bd358b7d31e76987a0b6fb1b0  2014            0.471835  \n",
       "...                                        ...                 ...  \n",
       "816ea64552b56ca901939e8506ff7802251dd783  2021            0.087352  \n",
       "8605228dc596ca1701a3e19d6eff49225e399b05  2021            0.087345  \n",
       "95900962a264ce89610877a323334c441c93c3b2  2019            0.087227  \n",
       "b2c70c4d23c98dd4e77234fe0720595d3d565a12  2021            0.086073  \n",
       "fd6dc29630b4f8e9c88f3da070be23f6ce0e28d9  2022            0.085388  \n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A copy of the main dataframe is created for this analysis.\n",
    "foundational_df = corpus_df.copy()\n",
    "\n",
    "# The metrics are normalized to a 0-1 scale to allow for fair comparison.\n",
    "foundational_df['norm_overall'] = foundational_df['overall_citations'] / foundational_df['overall_citations'].max()\n",
    "foundational_df['norm_in_corpus'] = foundational_df['in_corpus_citations'] / foundational_df['in_corpus_citations'].max()\n",
    "foundational_df['norm_pagerank'] = foundational_df['pagerank'] / foundational_df['pagerank'].max()\n",
    "\n",
    "# The weighted Foundational Score is calculated.\n",
    "# In-corpus citations are weighted most heavily to prioritize domain relevance.\n",
    "weights = {'in_corpus': 0.5, 'pagerank': 0.3, 'overall': 0.2}\n",
    "foundational_df['foundational_score'] = (\n",
    "    weights['in_corpus'] * foundational_df['norm_in_corpus'] +\n",
    "    weights['pagerank'] * foundational_df['norm_pagerank'] +\n",
    "    weights['overall'] * foundational_df['norm_overall']\n",
    ")\n",
    "\n",
    "# The top 100 foundational papers are selected.\n",
    "foundational_papers = foundational_df.sort_values('foundational_score', ascending=False).head(100)\n",
    "\n",
    "print(f\"Identified {len(foundational_papers)} foundational papers.\")\n",
    "display(foundational_papers[['title', 'year', 'foundational_score']].head(75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79db72",
   "metadata": {},
   "source": [
    "## 3. Bucket B: Identifying Rising Stars\n",
    "\n",
    "The \"Rising Stars\" are identified to counteract the citation bias towards older papers. This method first filters the corpus for recent publications (last 3 years). It then calculates a \"Citation Velocity\" for each recent paper, which measures the rate of citation accumulation. This process identifies new papers that are gaining impact most quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45ff4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 100 rising star papers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_velocity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "97ea7a24-9e39-4860-aeac-525d85d634ad",
       "rows": [
        [
         "1b1efa2f9731ab3801c46bfc877695d41e437406",
         "An Online Reinforcement Learning-Based Energy Management Strategy for Microgrids With Centralized Control",
         "2025",
         "60.0"
        ],
        [
         "7158277c0361f15a7c67621f5940c4208c9c46ce",
         "Optimizing renewable energy systems through artificial intelligence: Review and future prospects",
         "2024",
         "52.0"
        ],
        [
         "5432468c6ab917ae8540be8e2086da301b59461e",
         "Deep Learning and Artificial Intelligence in Sustainability: A Review of SDGs, Renewable Energy, and Environmental Health",
         "2023",
         "40.0"
        ],
        [
         "ba54f632c4edf6aaa44bbdfc31d1942a379352c3",
         "Asynchronous Deep Reinforcement Learning for Collaborative Task Computing and On-Demand Resource Allocation in Vehicular Edge Computing",
         "2023",
         "36.333333333333336"
        ],
        [
         "14fbad4644fcefc0bb2ea5314bc65387a11b7b21",
         "AI and human-robot interaction: A review of recent advances and challenges",
         "2024",
         "29.5"
        ],
        [
         "84ab6f6310257588c94a6eff3b974017b0fa02a3",
         "A Tri-Level Demand Response Framework for EVCS Flexibility Enhancement in Coupled Power and Transportation Networks",
         "2025",
         "28.0"
        ],
        [
         "ab5ce9fb84e0f73b5f7315b6e75a227a3d39e699",
         "Next Generation of Electric Vehicles: AI-Driven Approaches for Predictive Maintenance and Battery Management",
         "2025",
         "27.0"
        ],
        [
         "c6478decdfff11ccbd085967c2f83aea11927a46",
         "Preference Transformer: Modeling Human Preferences using Transformers for RL",
         "2023",
         "26.333333333333332"
        ],
        [
         "47101a6a1492eba693d14021b23014491d14d73b",
         "Adaptive Silo Networks with Cloud Computing and Reinforcement Learning for Responsive Grain Storage",
         "2024",
         "22.5"
        ],
        [
         "18444c1729a63c97821a64a5d0b0588e20a0170b",
         "Edge Computation Offloading With Content Caching in 6G-Enabled IoV",
         "2024",
         "21.5"
        ],
        [
         "51e967ca333fd9b39fa7a739ece2efe4e33ec218",
         "AI-Empowered Methods for Smart Energy Consumption: A Review of Load Forecasting, Anomaly Detection and Demand Response",
         "2023",
         "21.333333333333332"
        ],
        [
         "ce9d299e510029971f2c229e4dba20ce1cfe9155",
         "Optimal Vehicle-to-Grid Control for Supplementary Frequency Regulation Using Deep Reinforcement Learning",
         "2023",
         "19.333333333333332"
        ],
        [
         "73f0d611b4c4fc5986ef0649b507da6465431743",
         "Survey on AI and Machine Learning Techniques for Microgrid Energy Management Systems",
         "2023",
         "19.333333333333332"
        ],
        [
         "33bef8ab31b2520301c798343da61d84e410585e",
         "Multi-Agent attention-based deep reinforcement learning for demand response in grid-responsive buildings",
         "2023",
         "19.0"
        ],
        [
         "0fba53d3ce7d7929a265d7fbdac88d01e584d5e6",
         "Coordinated Electric Vehicle Active and Reactive Power Control for Active Distribution Networks",
         "2023",
         "17.666666666666668"
        ],
        [
         "131c883ba268e63dbb7629ad36a4b848f980af63",
         "DRL-HEMS: Deep Reinforcement Learning Agent for Demand Response in Home Energy Management Systems Considering Customers and Operators Perspectives",
         "2023",
         "17.666666666666668"
        ],
        [
         "46cb7097390c5679cbb76a89ca0cff94bcb2fa9e",
         "Real-Time Operation Management for Battery Swapping-Charging System via Multi-Agent Deep Reinforcement Learning",
         "2023",
         "16.666666666666668"
        ],
        [
         "75bf60502ab1e9a1325f817c37ab83c4ee129037",
         "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning",
         "2025",
         "16.0"
        ],
        [
         "c23a54528d1dac66b1eeb16231988375867a6e6b",
         "Intelligent Path Planning of Underwater Robot Based on Reinforcement Learning",
         "2023",
         "16.0"
        ],
        [
         "b9f39a73b67707a95b3a5eaacc7e28af808b455e",
         "PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful Navigators",
         "2024",
         "15.0"
        ],
        [
         "c0c6034d1d13e6e082189632d3b39ca2f8fa831c",
         "Review and Evaluation of Reinforcement Learning Frameworks on Smart Grid Applications",
         "2023",
         "14.666666666666666"
        ],
        [
         "f72246848e568b559a52b3a3e5584c3f01870dbc",
         "A Graph Reinforcement Learning-Based Decision-Making Platform for Real-Time Charging Navigation of Urban Electric Vehicles",
         "2023",
         "14.0"
        ],
        [
         "0a922b4fdbe923b5161b5c6f5adfe586bf7304c3",
         "Large language models will not replace healthcare professionals: curbing popular fears and hype",
         "2023",
         "14.0"
        ],
        [
         "8f2f8aac4386d081e096ee3593ef71da096dce12",
         "Distribution Grid Topology and Parameter Estimation Using Deep-Shallow Neural Network With Physical Consistency",
         "2024",
         "13.0"
        ],
        [
         "f96af696ede0eb7fd490d4a999dd4739008d9f9a",
         "Multiagent Deep Reinforcement Learning for Electric Vehicle Fast Charging Station Pricing Game in Electricity-Transportation Nexus",
         "2024",
         "13.0"
        ],
        [
         "3afbead850747d4a98c24cca0af1f5e78a128396",
         "An effective energy management Layout-Based reinforcement learning for household demand response in digital twin simulation",
         "2023",
         "13.0"
        ],
        [
         "bb610534e7d50800706375584f888633db45ad43",
         "An Intelligent Privacy Preservation Scheme for EV Charging Infrastructure",
         "2023",
         "12.666666666666666"
        ],
        [
         "6403ba7f125fc6a186eb36a50196ef3de0d1de18",
         "Development of improved reinforcement learning smart charging strategy for electric vehicle fleet",
         "2023",
         "12.666666666666666"
        ],
        [
         "7b3c36c30bc27813e7cc5a9d4bd0570e7169e467",
         "Deep Reinforcement Learning for Charging Scheduling of Electric Vehicles Considering Distribution Network Voltage Stability",
         "2023",
         "12.0"
        ],
        [
         "6ae2240d21c96f8c703409fc0e94ed0e0a9f61c7",
         "A Survey on Causal Reinforcement Learning",
         "2023",
         "11.666666666666666"
        ],
        [
         "f84addd8654b657e0286a44ba7c972f3cac0007f",
         "Physics-Informed Machine Learning for Data Anomaly Detection, Classification, Localization, and Mitigation: A Review, Challenges, and Path Forward",
         "2023",
         "11.666666666666666"
        ],
        [
         "4d17f729fa0872ed663079afc865365ac7f5cf9c",
         "An Augmented Lagrangian-Based Safe Reinforcement Learning Algorithm for Carbon-Oriented Optimal Scheduling of EV Aggregators",
         "2024",
         "11.5"
        ],
        [
         "a92dc27ba04348cdf71682bfa77081d8a478b78f",
         "Machine learning for the physics of climate",
         "2024",
         "11.5"
        ],
        [
         "c31bf59b8b8649f749a2ba84648a4ccaf72b6f13",
         "Electric Vehicles Management in Distribution Network: A Data-Efficient Bi-Level Safe Deep Reinforcement Learning Method",
         "2025",
         "11.0"
        ],
        [
         "d9d0f7ee33d72f1c8195101d5eca60f150fddb70",
         "Automatic Transportation Mode Classification Using a Deep Reinforcement Learning Approach With Smartphone Sensors",
         "2024",
         "11.0"
        ],
        [
         "302dfc2277f4f90ec8dba77eb3ff78977cd6b150",
         "Explainable multi-agent deep reinforcement learning for real-time demand response towards sustainable manufacturing",
         "2023",
         "10.666666666666666"
        ],
        [
         "1464671de9e6b0c58520588244d28cb4bf3a259d",
         "Blockchain and Federated Reinforcement Learning for Vehicle-to-Everything Energy Trading in Smart Grids",
         "2024",
         "10.5"
        ],
        [
         "401e43955af440bc2e8d1641f71aaf59249a524a",
         "EvoX: A Distributed GPU-Accelerated Framework for Scalable Evolutionary Computation",
         "2023",
         "10.333333333333334"
        ],
        [
         "d2cbea2df9043c30a93850eda54be4324faa55f5",
         "Optimal Priority Rule-Enhanced Deep Reinforcement Learning for Charging Scheduling in an Electric Vehicle Battery Swapping Station",
         "2023",
         "10.333333333333334"
        ],
        [
         "47515a9f39e06575e4e7f167c4a88966f88f9170",
         "Enhancing cyber-resilience in integrated energy system scheduling with demand response using deep reinforcement learning",
         "2023",
         "10.0"
        ],
        [
         "1a81ecddc4a8d8dc48af6202d31f8562a9c07309",
         "RLCharge: Imitative Multi-Agent Spatiotemporal Reinforcement Learning for Electric Vehicle Charging Station Recommendation",
         "2023",
         "10.0"
        ],
        [
         "68a22a4272e1b9030255a6bccb13c6b2e6bdb5b1",
         "Distributed Training and Distributed Execution-Based Stackelberg Multi-Agent Reinforcement Learning for EV Charging Scheduling",
         "2023",
         "10.0"
        ],
        [
         "0327596d1c83506035a2372eb649d5c16d9515be",
         "Comprehensive Overview of Reward Engineering and Shaping in Advancing Reinforcement Learning Applications",
         "2024",
         "10.0"
        ],
        [
         "e495d6ca8b57d3056ea6859d0bf134ae44dbecef",
         "Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning",
         "2024",
         "9.5"
        ],
        [
         "78d4c93ae1e7eda970e602085a270d24f10e0ef0",
         "Novel Architecture of Energy Management Systems Based on Deep Reinforcement Learning in Microgrid",
         "2024",
         "9.5"
        ],
        [
         "8f12fa6e3b9aa8e0ea908b34a2850d89c1d0c537",
         "AI-Driven Approach for Enhancing Sustainability in Urban Public Transportation",
         "2024",
         "9.5"
        ],
        [
         "43fe11d01e837cf1e9c50dd988fef8f4033c4fb0",
         "Green Edge Intelligence for Smart Management of a FANET in Disaster-Recovery Scenarios",
         "2023",
         "9.0"
        ],
        [
         "a6ed003703b52aa7de285d19ea2b09326ba04ae4",
         "Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation",
         "2023",
         "9.0"
        ],
        [
         "4376e282954ec59eaeca345ce4ec99219a075670",
         "A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization",
         "2025",
         "9.0"
        ],
        [
         "bcbc7369e93a9766ddefb58900ce19f5728d2da7",
         "Video-Holmes: Can MLLM Think Like Holmes for Complex Video Reasoning?",
         "2025",
         "9.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>citation_velocity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1b1efa2f9731ab3801c46bfc877695d41e437406</th>\n",
       "      <td>An Online Reinforcement Learning-Based Energy ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158277c0361f15a7c67621f5940c4208c9c46ce</th>\n",
       "      <td>Optimizing renewable energy systems through ar...</td>\n",
       "      <td>2024</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432468c6ab917ae8540be8e2086da301b59461e</th>\n",
       "      <td>Deep Learning and Artificial Intelligence in S...</td>\n",
       "      <td>2023</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba54f632c4edf6aaa44bbdfc31d1942a379352c3</th>\n",
       "      <td>Asynchronous Deep Reinforcement Learning for C...</td>\n",
       "      <td>2023</td>\n",
       "      <td>36.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14fbad4644fcefc0bb2ea5314bc65387a11b7b21</th>\n",
       "      <td>AI and human-robot interaction: A review of re...</td>\n",
       "      <td>2024</td>\n",
       "      <td>29.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87ad649e29687275b1bd288104ec0238c321a72f</th>\n",
       "      <td>Reinforcement Learning-Based Demand Response M...</td>\n",
       "      <td>2023</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcc4cc6d47fd5cb583bc3ce7f36c2b6ce1610866</th>\n",
       "      <td>AI-DRIVEN OPTIMIZATION IN RENEWABLE HYDROGEN P...</td>\n",
       "      <td>2025</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322a4ac24b1e43ae684e0d66ae67e6e256bf377</th>\n",
       "      <td>A Reinforcement Learning Approach for Integrat...</td>\n",
       "      <td>2023</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c33a21e4215a5cd690ca8e2bb0d770b45adf5c89</th>\n",
       "      <td>Reinforcing the Diffusion Chain of Lateral Tho...</td>\n",
       "      <td>2025</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61024282f1523543a5b06326cb58c9b6ad14cdd1</th>\n",
       "      <td>DiffuCoder: Understanding and Improving Masked...</td>\n",
       "      <td>2025</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "paperId                                                                                       \n",
       "1b1efa2f9731ab3801c46bfc877695d41e437406  An Online Reinforcement Learning-Based Energy ...   \n",
       "7158277c0361f15a7c67621f5940c4208c9c46ce  Optimizing renewable energy systems through ar...   \n",
       "5432468c6ab917ae8540be8e2086da301b59461e  Deep Learning and Artificial Intelligence in S...   \n",
       "ba54f632c4edf6aaa44bbdfc31d1942a379352c3  Asynchronous Deep Reinforcement Learning for C...   \n",
       "14fbad4644fcefc0bb2ea5314bc65387a11b7b21  AI and human-robot interaction: A review of re...   \n",
       "...                                                                                     ...   \n",
       "87ad649e29687275b1bd288104ec0238c321a72f  Reinforcement Learning-Based Demand Response M...   \n",
       "dcc4cc6d47fd5cb583bc3ce7f36c2b6ce1610866  AI-DRIVEN OPTIMIZATION IN RENEWABLE HYDROGEN P...   \n",
       "8322a4ac24b1e43ae684e0d66ae67e6e256bf377  A Reinforcement Learning Approach for Integrat...   \n",
       "c33a21e4215a5cd690ca8e2bb0d770b45adf5c89  Reinforcing the Diffusion Chain of Lateral Tho...   \n",
       "61024282f1523543a5b06326cb58c9b6ad14cdd1  DiffuCoder: Understanding and Improving Masked...   \n",
       "\n",
       "                                          year  citation_velocity  \n",
       "paperId                                                            \n",
       "1b1efa2f9731ab3801c46bfc877695d41e437406  2025          60.000000  \n",
       "7158277c0361f15a7c67621f5940c4208c9c46ce  2024          52.000000  \n",
       "5432468c6ab917ae8540be8e2086da301b59461e  2023          40.000000  \n",
       "ba54f632c4edf6aaa44bbdfc31d1942a379352c3  2023          36.333333  \n",
       "14fbad4644fcefc0bb2ea5314bc65387a11b7b21  2024          29.500000  \n",
       "...                                        ...                ...  \n",
       "87ad649e29687275b1bd288104ec0238c321a72f  2023           7.000000  \n",
       "dcc4cc6d47fd5cb583bc3ce7f36c2b6ce1610866  2025           7.000000  \n",
       "8322a4ac24b1e43ae684e0d66ae67e6e256bf377  2023           7.000000  \n",
       "c33a21e4215a5cd690ca8e2bb0d770b45adf5c89  2025           7.000000  \n",
       "61024282f1523543a5b06326cb58c9b6ad14cdd1  2025           7.000000  \n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A copy of the main dataframe is created and filtered for recent papers.\n",
    "current_year = 2025\n",
    "rising_stars_df = corpus_df[corpus_df['year'] >= (current_year - 2)].copy()\n",
    "\n",
    "# Citation velocity is calculated.\n",
    "# 1 is added to the denominator to avoid division by zero for papers published in the current year.\n",
    "rising_stars_df['citation_velocity'] = rising_stars_df['overall_citations'] / (current_year - rising_stars_df['year'] + 1)\n",
    "\n",
    "# The top 100 rising stars are selected.\n",
    "rising_stars = rising_stars_df.sort_values('citation_velocity', ascending=False).head(100)\n",
    "\n",
    "print(f\"Identified {len(rising_stars)} rising star papers.\")\n",
    "display(rising_stars[['title', 'year', 'citation_velocity']].head(75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a14c8d",
   "metadata": {},
   "source": [
    "## Bucket C: Identifying the Pre-publication Frontier\n",
    "\n",
    "To capture the most recent, pre-publication research that has not yet had time to accumulate citations, this step identifies promising papers from arXiv. The methodology uses semantic similarity to find recent preprints that are most closely related to the core themes of the established \"Rising Stars.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c15cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifying Pre-publication Frontier papers...\n",
      "Found 56 recent arXiv papers.\n",
      "Generating embeddings for similarity search...\n",
      "Identified 25 pre-publication papers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "paperId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "similarity_score",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "3bc34efd-be70-43e7-92f1-167aab0b8910",
       "rows": [
        [
         "dd3c8ed71b80fb7d4dd6fb68b409e21f984e2f9b",
         "Deep Reinforcement Learning-Based Optimization of Second-Life Battery Utilization in Electric Vehicles Charging Stations",
         "0.8056661"
        ],
        [
         "f34925ad0d98a506eec2934e3435eef12554969e",
         "A Generative Model Enhanced Multi-Agent Reinforcement Learning Method for Electric Vehicle Charging Navigation",
         "0.7750524"
        ],
        [
         "e9977d1686710191032d176ff32f1f5bb12c0704",
         "Replicating the behaviour of electric vehicle drivers using an agent-based reinforcement learning model",
         "0.71462566"
        ],
        [
         "83e899f71cf32a769de2bc786c63810a2e1320db",
         "Integration of Multi-Mode Preference into Home Energy Management System Using Deep Reinforcement Learning",
         "0.7140964"
        ],
        [
         "d137a77a7abb3c19ff678f234756f2b6a00b6b71",
         "LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading",
         "0.6661477"
        ],
        [
         "df96e0f65c5743c9459c4d5ae3e022741cdb8f2c",
         "Deep Learning Innovations for Energy Efficiency: Advances in Non-Intrusive Load Monitoring and EV Charging Optimization for a Sustainable Grid",
         "0.64696217"
        ],
        [
         "75bf60502ab1e9a1325f817c37ab83c4ee129037",
         "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning",
         "0.6215048"
        ],
        [
         "4376e282954ec59eaeca345ce4ec99219a075670",
         "A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization",
         "0.6212463"
        ],
        [
         "3429d178fc117ccef92fbf6910ad4cff34290094",
         "Reinforcement Learning-Driven Plant-Wide Refinery Planning Using Model Decomposition",
         "0.6207891"
        ],
        [
         "1dce46450c1a08aa4cc0da964162733b67909fc0",
         "A Roadmap Towards Improving Multi-Agent Reinforcement Learning With Causal Discovery And Inference",
         "0.59853506"
        ],
        [
         "4b6d543fa526897d9006dff7856099cbbf25c381",
         "Optimizing Electric Vehicles Charging using Large Language Models and Graph Neural Networks",
         "0.5903614"
        ],
        [
         "e6a78146f35ebb45474326f388b4e10c0f55d513",
         "Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)",
         "0.58269465"
        ],
        [
         "727974a27c489fc565b9bc393373c142b257abd2",
         "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments",
         "0.58117515"
        ],
        [
         "540c794ac6b2dd8f6baf3573723f7cd96e0d1bed",
         "Algorithmic Control Improves Residential Building Energy and EV Management when PV Capacity is High but Battery Capacity is Low",
         "0.57782423"
        ],
        [
         "0d5be3ce511dede9902583bbfd3c393bfea786ae",
         "Intelligent Load Balancing Systems using Reinforcement Learning System",
         "0.5776728"
        ],
        [
         "ccc3e570c5efaa7a153484d91e5acda0df40e10c",
         "Reinforcement Learning Based Symbolic Regression for Load Modeling",
         "0.56146455"
        ],
        [
         "ab2cacd24cf1c25adc325e1ef13b58bfacadb5f4",
         "Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains",
         "0.5585393"
        ],
        [
         "2e385b522f71aa9ee27feb05f5ceeb8a663ab95f",
         "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information",
         "0.5562544"
        ],
        [
         "b2886354eead522505af60d6881ad3e9b8e36b76",
         "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic",
         "0.55239254"
        ],
        [
         "b1d625e2e6e1b939fdcd148a2e00dff0bb097041",
         "Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning",
         "0.54823357"
        ],
        [
         "47ea295a79c58b04eb71278e1f48afa9650ebb2f",
         "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning",
         "0.5344112"
        ],
        [
         "e5d95b7a7f974bc8f797c9be411515d8fb7239ef",
         "Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies",
         "0.52555937"
        ],
        [
         "30260bdeffc4a48f8828af71701284dc9474e8f3",
         "Control of Renewable Energy Communities using AI and Real-World Data",
         "0.5253125"
        ],
        [
         "4251bdcfc1b667866ec301532c49090b69d2b73c",
         "A Graphical Approach to State Variable Selection in Off-policy Learning",
         "0.5163379"
        ],
        [
         "633e9ab9571712536cf418af59ddf2a9992f9d9b",
         "AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study",
         "0.51276624"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 25
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dd3c8ed71b80fb7d4dd6fb68b409e21f984e2f9b</th>\n",
       "      <td>Deep Reinforcement Learning-Based Optimization...</td>\n",
       "      <td>0.805666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f34925ad0d98a506eec2934e3435eef12554969e</th>\n",
       "      <td>A Generative Model Enhanced Multi-Agent Reinfo...</td>\n",
       "      <td>0.775052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e9977d1686710191032d176ff32f1f5bb12c0704</th>\n",
       "      <td>Replicating the behaviour of electric vehicle ...</td>\n",
       "      <td>0.714626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83e899f71cf32a769de2bc786c63810a2e1320db</th>\n",
       "      <td>Integration of Multi-Mode Preference into Home...</td>\n",
       "      <td>0.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d137a77a7abb3c19ff678f234756f2b6a00b6b71</th>\n",
       "      <td>LLM-Enhanced Multi-Agent Reinforcement Learnin...</td>\n",
       "      <td>0.666148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df96e0f65c5743c9459c4d5ae3e022741cdb8f2c</th>\n",
       "      <td>Deep Learning Innovations for Energy Efficienc...</td>\n",
       "      <td>0.646962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75bf60502ab1e9a1325f817c37ab83c4ee129037</th>\n",
       "      <td>RAD: Training an End-to-End Driving Policy via...</td>\n",
       "      <td>0.621505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376e282954ec59eaeca345ce4ec99219a075670</th>\n",
       "      <td>A Unified Pairwise Framework for RLHF: Bridgin...</td>\n",
       "      <td>0.621246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429d178fc117ccef92fbf6910ad4cff34290094</th>\n",
       "      <td>Reinforcement Learning-Driven Plant-Wide Refin...</td>\n",
       "      <td>0.620789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1dce46450c1a08aa4cc0da964162733b67909fc0</th>\n",
       "      <td>A Roadmap Towards Improving Multi-Agent Reinfo...</td>\n",
       "      <td>0.598535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4b6d543fa526897d9006dff7856099cbbf25c381</th>\n",
       "      <td>Optimizing Electric Vehicles Charging using La...</td>\n",
       "      <td>0.590361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6a78146f35ebb45474326f388b4e10c0f55d513</th>\n",
       "      <td>Raw2Drive: Reinforcement Learning with Aligned...</td>\n",
       "      <td>0.582695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727974a27c489fc565b9bc393373c142b257abd2</th>\n",
       "      <td>Causal Knowledge Transfer for Multi-Agent Rein...</td>\n",
       "      <td>0.581175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540c794ac6b2dd8f6baf3573723f7cd96e0d1bed</th>\n",
       "      <td>Algorithmic Control Improves Residential Build...</td>\n",
       "      <td>0.577824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0d5be3ce511dede9902583bbfd3c393bfea786ae</th>\n",
       "      <td>Intelligent Load Balancing Systems using Reinf...</td>\n",
       "      <td>0.577673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccc3e570c5efaa7a153484d91e5acda0df40e10c</th>\n",
       "      <td>Reinforcement Learning Based Symbolic Regressi...</td>\n",
       "      <td>0.561465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2cacd24cf1c25adc325e1ef13b58bfacadb5f4</th>\n",
       "      <td>Adaptive Inventory Strategies using Deep Reinf...</td>\n",
       "      <td>0.558539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e385b522f71aa9ee27feb05f5ceeb8a663ab95f</th>\n",
       "      <td>Decentralizing Multi-Agent Reinforcement Learn...</td>\n",
       "      <td>0.556254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2886354eead522505af60d6881ad3e9b8e36b76</th>\n",
       "      <td>Causal Policy Learning in Reinforcement Learni...</td>\n",
       "      <td>0.552393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1d625e2e6e1b939fdcd148a2e00dff0bb097041</th>\n",
       "      <td>Towards Efficient Online Tuning of VLM Agents ...</td>\n",
       "      <td>0.548234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47ea295a79c58b04eb71278e1f48afa9650ebb2f</th>\n",
       "      <td>Router-R1: Teaching LLMs Multi-Round Routing a...</td>\n",
       "      <td>0.534411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5d95b7a7f974bc8f797c9be411515d8fb7239ef</th>\n",
       "      <td>Learning Nonlinear Causal Reductions to Explai...</td>\n",
       "      <td>0.525559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30260bdeffc4a48f8828af71701284dc9474e8f3</th>\n",
       "      <td>Control of Renewable Energy Communities using ...</td>\n",
       "      <td>0.525312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251bdcfc1b667866ec301532c49090b69d2b73c</th>\n",
       "      <td>A Graphical Approach to State Variable Selecti...</td>\n",
       "      <td>0.516338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633e9ab9571712536cf418af59ddf2a9992f9d9b</th>\n",
       "      <td>AI-Based Demand Forecasting and Load Balancing...</td>\n",
       "      <td>0.512766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "paperId                                                                                       \n",
       "dd3c8ed71b80fb7d4dd6fb68b409e21f984e2f9b  Deep Reinforcement Learning-Based Optimization...   \n",
       "f34925ad0d98a506eec2934e3435eef12554969e  A Generative Model Enhanced Multi-Agent Reinfo...   \n",
       "e9977d1686710191032d176ff32f1f5bb12c0704  Replicating the behaviour of electric vehicle ...   \n",
       "83e899f71cf32a769de2bc786c63810a2e1320db  Integration of Multi-Mode Preference into Home...   \n",
       "d137a77a7abb3c19ff678f234756f2b6a00b6b71  LLM-Enhanced Multi-Agent Reinforcement Learnin...   \n",
       "df96e0f65c5743c9459c4d5ae3e022741cdb8f2c  Deep Learning Innovations for Energy Efficienc...   \n",
       "75bf60502ab1e9a1325f817c37ab83c4ee129037  RAD: Training an End-to-End Driving Policy via...   \n",
       "4376e282954ec59eaeca345ce4ec99219a075670  A Unified Pairwise Framework for RLHF: Bridgin...   \n",
       "3429d178fc117ccef92fbf6910ad4cff34290094  Reinforcement Learning-Driven Plant-Wide Refin...   \n",
       "1dce46450c1a08aa4cc0da964162733b67909fc0  A Roadmap Towards Improving Multi-Agent Reinfo...   \n",
       "4b6d543fa526897d9006dff7856099cbbf25c381  Optimizing Electric Vehicles Charging using La...   \n",
       "e6a78146f35ebb45474326f388b4e10c0f55d513  Raw2Drive: Reinforcement Learning with Aligned...   \n",
       "727974a27c489fc565b9bc393373c142b257abd2  Causal Knowledge Transfer for Multi-Agent Rein...   \n",
       "540c794ac6b2dd8f6baf3573723f7cd96e0d1bed  Algorithmic Control Improves Residential Build...   \n",
       "0d5be3ce511dede9902583bbfd3c393bfea786ae  Intelligent Load Balancing Systems using Reinf...   \n",
       "ccc3e570c5efaa7a153484d91e5acda0df40e10c  Reinforcement Learning Based Symbolic Regressi...   \n",
       "ab2cacd24cf1c25adc325e1ef13b58bfacadb5f4  Adaptive Inventory Strategies using Deep Reinf...   \n",
       "2e385b522f71aa9ee27feb05f5ceeb8a663ab95f  Decentralizing Multi-Agent Reinforcement Learn...   \n",
       "b2886354eead522505af60d6881ad3e9b8e36b76  Causal Policy Learning in Reinforcement Learni...   \n",
       "b1d625e2e6e1b939fdcd148a2e00dff0bb097041  Towards Efficient Online Tuning of VLM Agents ...   \n",
       "47ea295a79c58b04eb71278e1f48afa9650ebb2f  Router-R1: Teaching LLMs Multi-Round Routing a...   \n",
       "e5d95b7a7f974bc8f797c9be411515d8fb7239ef  Learning Nonlinear Causal Reductions to Explai...   \n",
       "30260bdeffc4a48f8828af71701284dc9474e8f3  Control of Renewable Energy Communities using ...   \n",
       "4251bdcfc1b667866ec301532c49090b69d2b73c  A Graphical Approach to State Variable Selecti...   \n",
       "633e9ab9571712536cf418af59ddf2a9992f9d9b  AI-Based Demand Forecasting and Load Balancing...   \n",
       "\n",
       "                                          similarity_score  \n",
       "paperId                                                     \n",
       "dd3c8ed71b80fb7d4dd6fb68b409e21f984e2f9b          0.805666  \n",
       "f34925ad0d98a506eec2934e3435eef12554969e          0.775052  \n",
       "e9977d1686710191032d176ff32f1f5bb12c0704          0.714626  \n",
       "83e899f71cf32a769de2bc786c63810a2e1320db          0.714096  \n",
       "d137a77a7abb3c19ff678f234756f2b6a00b6b71          0.666148  \n",
       "df96e0f65c5743c9459c4d5ae3e022741cdb8f2c          0.646962  \n",
       "75bf60502ab1e9a1325f817c37ab83c4ee129037          0.621505  \n",
       "4376e282954ec59eaeca345ce4ec99219a075670          0.621246  \n",
       "3429d178fc117ccef92fbf6910ad4cff34290094          0.620789  \n",
       "1dce46450c1a08aa4cc0da964162733b67909fc0          0.598535  \n",
       "4b6d543fa526897d9006dff7856099cbbf25c381          0.590361  \n",
       "e6a78146f35ebb45474326f388b4e10c0f55d513          0.582695  \n",
       "727974a27c489fc565b9bc393373c142b257abd2          0.581175  \n",
       "540c794ac6b2dd8f6baf3573723f7cd96e0d1bed          0.577824  \n",
       "0d5be3ce511dede9902583bbfd3c393bfea786ae          0.577673  \n",
       "ccc3e570c5efaa7a153484d91e5acda0df40e10c          0.561465  \n",
       "ab2cacd24cf1c25adc325e1ef13b58bfacadb5f4          0.558539  \n",
       "2e385b522f71aa9ee27feb05f5ceeb8a663ab95f          0.556254  \n",
       "b2886354eead522505af60d6881ad3e9b8e36b76          0.552393  \n",
       "b1d625e2e6e1b939fdcd148a2e00dff0bb097041          0.548234  \n",
       "47ea295a79c58b04eb71278e1f48afa9650ebb2f          0.534411  \n",
       "e5d95b7a7f974bc8f797c9be411515d8fb7239ef          0.525559  \n",
       "30260bdeffc4a48f8828af71701284dc9474e8f3          0.525312  \n",
       "4251bdcfc1b667866ec301532c49090b69d2b73c          0.516338  \n",
       "633e9ab9571712536cf418af59ddf2a9992f9d9b          0.512766  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- BUCKET C: PRE-PUBLICATION FRONTIER ---\n",
    "print(\"\\nIdentifying Pre-publication Frontier papers...\")\n",
    "\n",
    "# It first filters the corpus for papers from the current year and from arXiv.\n",
    "recent_arxiv_df = corpus_df[(corpus_df['year'] == 2025) & (corpus_df['venue'] == 'arXiv.org')].copy()\n",
    "print(f\"Found {len(recent_arxiv_df)} recent arXiv papers.\")\n",
    "\n",
    "if not recent_arxiv_df.empty:\n",
    "    # An embedding model is initialized.\n",
    "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # It generates embeddings for the abstracts of the \"Rising Stars\" and recent arXiv papers.\n",
    "    print(\"Generating embeddings for similarity search...\")\n",
    "    rising_star_embeddings = embedding_model.encode(rising_stars['title'].tolist())\n",
    "    arxiv_embeddings = embedding_model.encode(recent_arxiv_df['title'].tolist())\n",
    "\n",
    "    # It creates a single \"prototype\" vector representing the core of the rising star research.\n",
    "    prototype_embedding = np.mean(rising_star_embeddings, axis=0).reshape(1, -1)\n",
    "\n",
    "    # It calculates the cosine similarity between each arXiv paper and the prototype.\n",
    "    similarities = cosine_similarity(arxiv_embeddings, prototype_embedding)\n",
    "    recent_arxiv_df['similarity_score'] = similarities\n",
    "\n",
    "    # The top 25 most similar preprints are selected.\n",
    "    pre_publication_papers = recent_arxiv_df.sort_values('similarity_score', ascending=False).head(25)\n",
    "\n",
    "    print(f\"Identified {len(pre_publication_papers)} pre-publication papers.\")\n",
    "    display(pre_publication_papers[['title', 'similarity_score']].head(25))\n",
    "else:\n",
    "    print(\"No recent arXiv papers found to form Bucket C.\")\n",
    "    pre_publication_papers = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a7679",
   "metadata": {},
   "source": [
    "## 4. Candidate Selection\n",
    "\n",
    "The final step combines the papers from the \"Foundational Pillars\" and \"Rising Stars\" buckets. The list is de-duplicated to create the final set of candidate papers. This balanced set, representing both established and emerging research, will be the focus of the in-depth content analysis in Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "266c375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique candidate papers for deep analysis: 225\n",
      "Candidate list saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b8cefb0c-134a-4c40-9a38-f44216fde6de",
       "rows": [
        [
         "0",
         "Model-Free Real-Time EV Charging Scheduling Based on Deep Reinforcement Learning",
         "2019"
        ],
        [
         "1",
         "Reinforcement learning for demand response: A review of algorithms and modeling techniques",
         "2019"
        ],
        [
         "2",
         "Incentive-based demand response for smart grid with reinforcement learning and deep neural network",
         "2019"
        ],
        [
         "3",
         "Reinforcement Learning-Based Plug-in Electric Vehicle Charging With Forecasted Price",
         "2017"
        ],
        [
         "4",
         "Optimal Demand Response Using Device-Based Reinforcement Learning",
         "2014"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-Free Real-Time EV Charging Scheduling Ba...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reinforcement learning for demand response: A ...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Incentive-based demand response for smart grid...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reinforcement Learning-Based Plug-in Electric ...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optimal Demand Response Using Device-Based Rei...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  year\n",
       "0  Model-Free Real-Time EV Charging Scheduling Ba...  2019\n",
       "1  Reinforcement learning for demand response: A ...  2019\n",
       "2  Incentive-based demand response for smart grid...  2019\n",
       "3  Reinforcement Learning-Based Plug-in Electric ...  2017\n",
       "4  Optimal Demand Response Using Device-Based Rei...  2014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The two buckets are combined into a single DataFrame.\n",
    "final_candidates = pd.concat([foundational_papers, rising_stars, pre_publication_papers])\n",
    "\n",
    "# The list is de-duplicated in case a paper appeared in both buckets.\n",
    "final_candidates.drop_duplicates(inplace=True)\n",
    "\n",
    "# The paperId index is reset to a column.\n",
    "final_candidates.reset_index(inplace=True)\n",
    "\n",
    "print(f\"Total unique candidate papers for deep analysis: {len(final_candidates)}\")\n",
    "\n",
    "# The final list is saved to a new CSV file for the next phase.\n",
    "final_candidates.to_csv('./data/processed/candidate_papers_for_analysis.csv', index=False)\n",
    "print(\"Candidate list saved.\")\n",
    "\n",
    "display(final_candidates[['title', 'year']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-rl-ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
